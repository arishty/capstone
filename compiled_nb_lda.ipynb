{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The following notebook is a compilation of code from \"LTD_EDA_ali.ipnyb\" which will be used in the final documentation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('LTD_rawevents.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'events_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-b30771b4e420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevents_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevents_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'WHAT TO DO?'\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m'Alex_targets'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'columns'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mevents_df_lab\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevents_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Alex_targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mevents_df_lab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlex_targets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevents_df_lab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlex_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mevents_df_lab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAlex_targets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'events_df' is not defined"
     ]
    }
   ],
   "source": [
    "events_df = events_df.rename({'WHAT TO DO?' : 'Alex_targets'}, axis='columns')\n",
    "events_df_lab = events_df.dropna(subset=['Alex_targets'])\n",
    "events_df_lab.Alex_targets = events_df_lab.Alex_targets.apply(lambda x: x.split(',')[0])\n",
    "events_df_lab.Alex_targets.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Processing event descriptions with Count Vectorizer/Bag of words method \n",
    "count_vec4 = CountVectorizer(ngram_range=(1,2), min_df=7, max_df=.9, max_features=5000)\n",
    "X_train_count4 = count_vec4.fit_transform(events_df_lab['Lem_words'])\n",
    "X_train_count4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running Naive Bayes classifier on bag of words, training on all events but the first 20\n",
    "multiNB = MultinomialNB()\n",
    "cntvecMNB = multiNB.fit(X_train_count4[20:,], events_df_lab.Alex_targets[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing NB classifier on first 20 events, viewing the predicted label output\n",
    "new_docs = X_train_count4[:20]\n",
    "cnt_predicted = cntvecMNB.predict(new_docs)\n",
    "cnt_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual labels Alex assigned for the first 20 events, for comparison\n",
    "events_df_lab.Alex_targets[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternative word processing method to plain count vectorizer: TfIdf (penalizing frequent words)\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# only includes words that appear more than 7x, and in less than 90% of events, and the top 5000 of those words\n",
    "tf_idf = TfidfVectorizer(ngram_range=(1,2), min_df=7, max_df=.9, max_features=5000) \n",
    "X_train_tf = tf_idf.fit_transform(events_df_lab['Lem_words'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fitting NB classifier on new TfIdf word data\n",
    "tf_idfMNB = multiNB.fit(X_train_tf[20:], events_df_lab.Alex_targets[20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Showing predictions for first 20 events\n",
    "new_docs_tf = X_train_tf[:20]\n",
    "tfidf_predicted = tf_idfMNB.predict(new_docs_tf)\n",
    "tfidf_predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing metric reports for both word count methods\n",
    "from sklearn import metrics\n",
    "print('The report for CountVectorizer word embedding through a Multinomial model:')\n",
    "print(metrics.classification_report(events_df_lab.Alex_targets[:20], cnt_predicted, target_names=events_df_lab.Alex_targets.unique() ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('The report for TF-IDF Vectorizer word embedding through a Multinomial model:')\n",
    "print(metrics.classification_report(events_df_lab.Alex_targets[:20], tfidf_predicted, target_names= events_df_lab.Alex_targets.unique()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA (Latent Dirichlet Allocation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "processed_docs  = []\n",
    "\n",
    "for doc in events_df_lab['Lem_words'][1:]:\n",
    "    doc = doc.split()\n",
    "    processed_docs.append(doc)\n",
    "    \n",
    "processed_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating bag of words with indices\n",
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep words that appear 7 or more times, but in less than 20% of events\n",
    "dictionary.filter_extremes(no_below=7, no_above=0.2, keep_n=50000)\n",
    "len(dictionary.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the first 10 dictionary entries of words in dataset\n",
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows how many time each word appears in specified document\n",
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf2 = gensim.models.LdaMulticore(tfidf_corpus, num_topics=6, id2word=dictionary, passes=2, eta=.01)\n",
    "pyLDAvis.gensim.prepare(lda_model_tfidf2, bow_corpus, dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# topic 1 - outdoor fairs, family / children friendly\n",
    "# topic 2 - locations /\"world\", artsy expos, comedy, wine/craft\n",
    "# topic 3 - local/ethnic culture\n",
    "# topic 4 - physical and mental wellness - active, but also comedy, literacy\n",
    "# topic 5 - food parties\n",
    "# topic 6 - southern cultural\n",
    "\n",
    "## 1 and 2 both have art as overlap"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
